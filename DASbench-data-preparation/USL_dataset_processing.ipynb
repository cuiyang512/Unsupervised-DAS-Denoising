{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0289458e-28ea-4c80-a8b0-b469c2f424f7",
   "metadata": {},
   "source": [
    "# Prediction code for Utah FORGE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c67daba-9a5a-48ed-80d1-2ae816ed0f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 15:45:24.903190: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-06 15:45:24.903215: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-06 15:45:24.904200: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 15:45:24.908879: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-06 15:45:25.424212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers, Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import *\n",
    "from keras.models import load_model\n",
    "from keras.utils import Sequence\n",
    "import tensorflow.keras.backend as K\n",
    "from numpy.random import seed\n",
    "\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "# Define paths for figures and models\n",
    "out_path = os.getenv('HOME')+\"/Yang/Data/DAS_data/German/raw_data/GrSk4_VP09_processed/\"\n",
    "fig_path = os.getenv('HOME')+\"/Yang/Data/DAS_data/German/raw_data/GrSk4_VP09_processed/figs/\"\n",
    "\n",
    "# Create directories if they do not exist\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e8556f-67bb-4b34-9d14-61ec772de157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 15:45:27.513588: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-06 15:45:27.513787: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-06 15:45:27.546142: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current processed data 1\n",
      "1180/1180 [==============================] - 3s 2ms/step\n",
      "current processed data 2\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 3\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 4\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 5\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 6\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 7\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 8\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 9\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 10\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 11\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 12\n",
      "1180/1180 [==============================] - 3s 2ms/step\n",
      "current processed data 13\n",
      "1180/1180 [==============================] - 2s 2ms/step\n",
      "current processed data 14\n",
      "1180/1180 [==============================] - 3s 2ms/step\n",
      "current processed data 15\n",
      "1180/1180 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Paths and parameters\n",
    "# Patch parameters\n",
    "w1, w2 = 24, 24\n",
    "z1, z2 = 6, 6\n",
    "batch_size = 1024\n",
    "drop_rate = 0.2\n",
    "epochs = 50\n",
    "v = 0.05\n",
    "data_path = os.getenv('HOME')+'/Yang/Data/DAS_data/German/raw_data/GrSk4_VP09_raw/'\n",
    "## load trained model\n",
    "model = load_model('./model/trained_model_1.h5')\n",
    "\n",
    "\n",
    "for i in range(1, 16):\n",
    "    data = np.load(f'{data_path}data_{i}.npy')\n",
    "    print(f'current processed data {i}')\n",
    "\n",
    "    # Apply patching\n",
    "    data_noisy = yc_patch(data, w1, w2, z1, z2)\n",
    "\n",
    "    ## prediction\n",
    "    out = model.predict(data_noisy)\n",
    "    out = np.transpose(out)\n",
    "\n",
    "    # unpatching\n",
    "    [n1, n2] = data.shape\n",
    "    predicted = yc_patch_inv(out,n1,n2,w1,w2,z1,z2)\n",
    "\n",
    "    np.save(f'{out_path}processed_data_{i+1}.npy', predicted)\n",
    "\n",
    "    # Constants\n",
    "    xx, yy = 100, 0.04\n",
    "    v1 = 1\n",
    "    \n",
    "    # Data dimensions and time axis\n",
    "    num_samples = data.shape[0]\n",
    "    num_samples_x = data.shape[1]\n",
    "    time_interval = 0.001\n",
    "    time = np.arange(0, num_samples) * time_interval\n",
    "    \n",
    "    # Annotation positions\n",
    "    mm = -0.03\n",
    "    nn = 1.05\n",
    "    \n",
    "    # Create the figure and subplots\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot 1: Raw data\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    im1 = ax1.imshow(\n",
    "        data, cmap=cseis(), vmin=-v, vmax=v, aspect='auto', extent=(1, num_samples_x, time[-1], 0)\n",
    "    )\n",
    "    ax1.set_xlabel(\"Trace\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Time (s)\", fontsize=12)\n",
    "    ax1.set_title('Raw Data', fontsize=14)\n",
    "    ax1.annotate('(a)', xy=(mm, nn), xycoords='axes fraction', fontsize=14, fontweight='bold', va='top')\n",
    "    \n",
    "    # Plot 2: Denoised data\n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    im2 = ax2.imshow(\n",
    "        predicted, cmap=cseis(), vmin=-v, vmax=v, aspect='auto', extent=(1, num_samples_x, time[-1], 0)\n",
    "    )\n",
    "    ax2.set_xlabel(\"Trace\", fontsize=12)\n",
    "    ax2.set_yticks([])  # Remove y-ticks for cleaner appearance\n",
    "    ax2.set_title('Denoised Data', fontsize=14)\n",
    "    ax2.annotate('(b)', xy=(mm, nn), xycoords='axes fraction', fontsize=14, fontweight='bold', va='top')\n",
    "    \n",
    "    # Plot 3: Removed noise\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    im3 = ax3.imshow(\n",
    "        (data - predicted), cmap=cseis(), vmin=-v, vmax=v, aspect='auto', extent=(1, num_samples_x, time[-1], 0)\n",
    "    )\n",
    "    ax3.set_xlabel(\"Trace\", fontsize=12)\n",
    "    ax3.set_yticks([])  # Remove y-ticks for cleaner appearance\n",
    "    ax3.set_title('Removed Noise', fontsize=14)\n",
    "    ax3.annotate('(c)', xy=(mm, nn), xycoords='axes fraction', fontsize=14, fontweight='bold', va='top')\n",
    "    \n",
    "    # Adjust layout and add colorbar\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.9)  # Make space for colorbar\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar_ax = fig.add_axes([0.905, 0.2, 0.015, 0.6])  # [left, bottom, width, height]\n",
    "    cb = plt.colorbar(im3, cax=cbar_ax)\n",
    "    cb.ax.tick_params(labelsize=8)\n",
    "    cbar_ticks = np.linspace(-v, v, 5)  # 5 ticks evenly spaced\n",
    "    cb.set_ticks(cbar_ticks)\n",
    "    cb.set_ticklabels([f'{tick:.2f}' for tick in cbar_ticks])\n",
    "    \n",
    "    # Save and show the plot\n",
    "    output_file = f'{fig_path}denoised_data_{i+1}.png'\n",
    "    plt.savefig(output_file, dpi=200)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
